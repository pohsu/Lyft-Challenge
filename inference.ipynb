{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images and paste predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame: 479/479\r"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = './images/stream1'\n",
    "image_paths = sorted(glob(os.path.join(IMAGE_DIR, 'CameraRGB', '*.png')))\n",
    "load_pb_path = './inference_pb/fused_graph.pb'\n",
    "tf.reset_default_graph()\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open(load_pb_path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    graph = tf.get_default_graph()\n",
    "    input_image = graph.get_tensor_by_name('input_image:0')\n",
    "    softmax = graph.get_tensor_by_name('softmax:0')\n",
    "    crop_up = 102\n",
    "    crop_down = 518\n",
    "    image_shape = [600,800,3]\n",
    "    results = []\n",
    "    f = 1\n",
    "    for image_file in image_paths:\n",
    "        rgb_frame = scipy.misc.imread(image_file)\n",
    "        crop_frame = rgb_frame[crop_up:crop_down,:,:]\n",
    "        crop_frame = np.expand_dims(crop_frame,0)\n",
    "        out = sess.run(softmax, feed_dict={input_image: crop_frame})[0]\n",
    "        out_arg = np.argmax(out,axis = 2)\n",
    "        # Look for red cars :)\n",
    "        binary_car_result = np.where(out_arg == 1,1,0)\n",
    "        binary_car_result = np.concatenate((np.zeros([crop_up,image_shape[1]]),binary_car_result), axis=0)\n",
    "        binary_car_result = np.concatenate((binary_car_result, np.zeros([image_shape[0]-crop_down,image_shape[1]])), axis=0)\n",
    "        mask_car = np.dot(np.expand_dims(binary_car_result, axis=2), np.array([[0, 255, 0, 127]]))\n",
    "        mask_car = scipy.misc.toimage(mask_car, mode=\"RGBA\")\n",
    "        # Look for road :)\n",
    "        binary_road_result = np.where(out_arg == 2,1,0)\n",
    "        binary_road_result = np.concatenate((np.zeros([crop_up,image_shape[1]]),binary_road_result), axis=0)\n",
    "        binary_road_result = np.concatenate((binary_road_result, np.zeros([image_shape[0]-crop_down,image_shape[1]])), axis=0)\n",
    "        mask_road = np.dot(np.expand_dims(binary_road_result, axis=2), np.array([[0, 0, 255, 127]]))\n",
    "        mask_road = scipy.misc.toimage(mask_road, mode=\"RGBA\")\n",
    "        frame_merge = scipy.misc.toimage(rgb_frame)\n",
    "        frame_merge.paste(mask_car, box=None, mask=mask_car)\n",
    "        frame_merge.paste(mask_road, box=None, mask=mask_road)\n",
    "        results.append(np.array(frame_merge))\n",
    "        print('Processing frame: {0}/{1}'.format(f,len(image_paths)),end='\\r')\n",
    "        f +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image sequence to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./videos/test_video1.mp4\n",
      "[MoviePy] Writing video ./videos/test_video1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:03<00:00, 151.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./videos/test_video1.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join('./videos','test_video1.mp4')\n",
    "output_clip = ImageSequenceClip(results, fps=25)\n",
    "output_clip.write_videofile(output_path, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./videos/test_video1.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
