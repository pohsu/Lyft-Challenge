{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ipynb\n",
    "This notebook is rather drafty and will be updated in a cleaner form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from glob import glob\n",
    "import re\n",
    "import time\n",
    "from imgaug import augmenters as iaa\n",
    "import model as build_ResNet\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR ='./save_models'\n",
    "LOAD_DIR ='./load_models'\n",
    "DATA_DIR ='./data'\n",
    "LOG_DIR = './log'\n",
    "train_path = os.path.join(DATA_DIR, 'Train')\n",
    "valid_path = os.path.join(DATA_DIR, 'Valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 12\n",
    "subversion = 8\n",
    "SAVE_DIR_TEST = os.path.join(SAVE_DIR, 'model_'+str(version)+'_'+ str(subversion))\n",
    "if not os.path.exists(SAVE_DIR_TEST):\n",
    "  os.makedirs(SAVE_DIR_TEST)\n",
    "save_txt_path = os.path.join(SAVE_DIR_TEST, 'log.txt')\n",
    "with open(save_txt_path, 'a') as f:\n",
    "  print(\"Train with (model.py to block3/unit_11) \",file=f)\n",
    "  \n",
    "for batch_size in [2]:\n",
    "  for l2_rate in [1e-4]:\n",
    "    for weights in [[0.3, 2.4, 0.3]]:\n",
    "        tf.reset_default_graph()\n",
    "        with tf.Session() as sess:\n",
    "          lrn_rate = 7e-4\n",
    "          epochs = 60\n",
    "          correct_label = tf.placeholder(tf.float32, [None, None, None,3], name = 'correct_label')\n",
    "          learning_rate = tf.placeholder(tf.float32,name='learning_rate')\n",
    "          L2 = tf.placeholder(tf.float32,name='L2')\n",
    "          load_model_path = os.path.join(LOAD_DIR, 'resnet_slim/ckpt')\n",
    "          tensors = build_ResNet.build_graph(sess, load_model_path, correct_label, learning_rate, num_classes, L2, weights)\n",
    "\n",
    "          var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)[544:]\n",
    "          partial_init_op = tf.variables_initializer(var_list, name='init')\n",
    "          sess.run(partial_init_op)\n",
    "          with open(save_txt_path, 'a') as f:\n",
    "            print(\"\\nB: {0}, L2: {1:3g}, W: {2}, lrn_rate: {3}\".format(batch_size, l2_rate, weights, lrn_rate),file=f)\n",
    "          print(\"\\nB: {0}, L2: {1:3g}, W: {2}, lrn_rate: {3}\".format(batch_size, l2_rate, weights, lrn_rate))\n",
    "          build_ResNet.train_nn_valid(sess, epochs, batch_size, lrn_rate, tensors, l2_rate, (train_path,valid_path), SAVE_DIR_TEST)\n",
    "          save_model_path = os.path.join(SAVE_DIR_TEST, 'ckpt')\n",
    "          saver = tf.train.Saver()\n",
    "          saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "  saver = tf.train.import_meta_graph('save_models/model_12_8/ckpt.meta')\n",
    "  saver.restore(sess, 'save_models/model_12_8/ckpt')\n",
    "  graph = tf.get_default_graph()\n",
    "  tensors = build_ResNet.load_train_tensors(graph)\n",
    "  \n",
    "  epochs = 20;\n",
    "  batch_size = 2\n",
    "  lrn_rate = 7e-5\n",
    "  l2_rate = 1e-4\n",
    "  \n",
    "  subversion = 8\n",
    "  SAVE_DIR_TEST = os.path.join(SAVE_DIR, 'model_'+str(version)+'_'+ str(subversion))\n",
    "  if not os.path.exists(SAVE_DIR_TEST):\n",
    "    os.makedirs(SAVE_DIR_TEST)\n",
    "\n",
    "  print(\"Start Re-trianing....\")\n",
    "  build_ResNet.train_nn_valid(sess, epochs, batch_size, lrn_rate, tensors, l2_rate, (train_path,valid_path), SAVE_DIR_TEST)\n",
    "  save_model_path = os.path.join(SAVE_DIR_TEST, 'ckpt')\n",
    "  saver = tf.train.Saver()\n",
    "  saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert placeholder to constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INF_DIR = os.path.join(SAVE_DIR, 'model_12_8_1')\n",
    "save_inf_path = os.path.join(SAVE_INF_DIR,'ckpt')\n",
    "load_weight_path = os.path.join(SAVE_DIR, 'model_12_8/ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "  build_ResNet.build_graph_inference(sess, './load_models/resnet_slim_inference/ckpt', num_classes)\n",
    "  saver = tf.train.Saver()\n",
    "  saver.restore(sess, load_weight_path)\n",
    "  saver.save(sess, save_inf_path)\n",
    "  tf.train.write_graph(sess.graph.as_graph_def(), SAVE_INF_DIR, \"base_graph.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate testset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INF_DIR = os.path.join(SAVE_DIR, 'model_12_8_1')\n",
    "save_inf_path = os.path.join(SAVE_INF_DIR,'ckpt')\n",
    "load_weight_path = os.path.join(SAVE_DIR, 'model_12_8/ckpt')\n",
    "test_path = os.path.join('./images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "  saver = tf.train.import_meta_graph(save_inf_path+'.meta')\n",
    "  saver.restore(sess, save_inf_path)\n",
    "  graph = tf.get_default_graph()\n",
    "  input_image = graph.get_tensor_by_name('input_image:0')\n",
    "  softmax = graph.get_tensor_by_name('softmax:0')\n",
    "  \n",
    "  images = []\n",
    "  labels = []\n",
    "  outs = []\n",
    "  valid_gen = build_ResNet.build_gen(test_path)\n",
    "  corrects = 0\n",
    "  pixels = 0\n",
    "  total_time = 0\n",
    "  total_images = 0\n",
    "  n_ii = [0] * num_classes\n",
    "  t_i = [0] * num_classes\n",
    "  n_ji = [0] * num_classes\n",
    "  z = 0\n",
    "  c_tp = 0\n",
    "  c_se = 0\n",
    "  c_re = 0\n",
    "  r_tp = 0\n",
    "  r_se = 0\n",
    "  r_re = 0\n",
    "  for image, label in valid_gen(8):\n",
    "    print ('{0}'.format(z), end='\\r')\n",
    "    z += 1\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "    feed_dict = {input_image: image}\n",
    "    total_images += image.shape[0]\n",
    "    t1 = time.time()\n",
    "    out = sess.run(softmax, feed_dict=feed_dict)\n",
    "    t2 = time.time()\n",
    "    total_time += t2-t1\n",
    "    outs.append(out)\n",
    "    corrects += np.sum(np.equal(np.argmax(out,axis = 3),np.argmax(label,axis = 3)))\n",
    "    pixels += label.shape[0]*label.shape[1]*label.shape[2]\n",
    "    for i in range(num_classes):\n",
    "      out_class = np.equal(np.argmax(out,axis = 3),i)\n",
    "      label_class = np.equal(np.argmax(label,axis = 3),i)\n",
    "      n_ii[i] += np.sum(out_class & label_class)\n",
    "      t_i[i] += np.sum(out_class)\n",
    "      n_ji[i] += np.sum(label_class)\n",
    "    out = np.argmax(out,axis = 3)\n",
    "    car_mask = np.where(out==1,1,0)\n",
    "    car_label_mask = label[:,:,:,1]\n",
    "    c_tp += np.sum(car_mask & car_label_mask)\n",
    "    c_se += np.sum(car_mask)\n",
    "    c_re += np.sum(car_label_mask)\n",
    "    road_mask = np.where(out==2,1,0)\n",
    "    road_label_mask = label[:,:,:,2]\n",
    "    r_tp += np.sum(road_mask & road_label_mask)\n",
    "    r_se += np.sum(road_mask)\n",
    "    r_re += np.sum(road_label_mask)\n",
    "\n",
    "  mean_IU = 0\n",
    "  mean_accuracy = 0\n",
    "  c_P = c_tp/c_se\n",
    "  c_R = c_tp/c_re\n",
    "  r_P = r_tp/r_se\n",
    "  r_R = r_tp/r_re\n",
    "  for i in range(num_classes):\n",
    "    mean_accuracy += n_ii[i]/t_i[i]/num_classes\n",
    "    mean_IU += n_ii[i]/(t_i[i]+n_ji[i]-n_ii[i])/num_classes\n",
    "  pixel_accuracy = np.sum(n_ii)/np.sum(t_i)\n",
    "  \n",
    "  print(\"Pixel Accuracy: {0:3g}, Mean Accuracy: {1:3g}, Mean IU: {2:3g}\".format(pixel_accuracy,mean_accuracy,mean_IU))\n",
    "  print(\"Car Precision: {0:.3g} | Car Recall: {1:.3g} | Road Precision: {2:.3g} | Road Recall: {3:.3g} \".format(c_P,c_R,r_P,r_R))\n",
    "  print(\"FPS: {0:3g}\".format(total_images/total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "idx = random.randint(0,len(images)-1)\n",
    "idxx = random.randint(0,images[idx].shape[0]-1)\n",
    "\n",
    "image = images[idx][idxx]\n",
    "label = labels[idx][idxx]\n",
    "out_car = np.equal(np.argmax(outs[idx][idxx],axis =2),1)\n",
    "mask_car = np.dot(out_car.reshape([416,800,1]), np.array([[0, 255, 0, 127]]))\n",
    "mask_car = scipy.misc.toimage(mask_car, mode=\"RGBA\")\n",
    "out_road = np.equal(np.argmax(outs[idx][idxx],axis =2),2)\n",
    "mask_road = np.dot(out_road.reshape([416,800,1]), np.array([[0, 0, 255, 127]]))\n",
    "mask_road = scipy.misc.toimage(mask_road, mode=\"RGBA\")\n",
    "image_merge = scipy.misc.toimage(image)\n",
    "image_merge.paste(mask_car, box=None, mask=mask_car)\n",
    "image_merge.paste(mask_road, box=None, mask=mask_road)\n",
    "plt.subplot(131)\n",
    "plt.title('original_image')\n",
    "plt.imshow(image)\n",
    "plt.subplot(132)\n",
    "plt.title('gt_label')\n",
    "plt.imshow(labels[idx][idxx]*255)\n",
    "plt.subplot(133)\n",
    "plt.title('predicted_label')\n",
    "plt.imshow(image_merge)\n",
    "plt.gcf().set_size_inches(20,20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
