{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference_demo\n",
    "This notebook intends to demo how to use the pre-trained fused graph for sementic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from utils import load_image_label_paths, process_raw_data, read_image_label_raw, paste_mask\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test inference engine for CARLA RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Precision: 0.823 | Car Recall: 0.978 | Road Precision: 0.997 | Road Recall: 0.992 \n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = './data/Test'\n",
    "image_paths, label_paths = load_image_label_paths(DATA_DIR,sort=True)\n",
    "load_pb_path = './inference_pb/fused_graph.pb'\n",
    "tf.reset_default_graph()\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    gd = tf.GraphDef()\n",
    "    with tf.gfile.Open(load_pb_path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        gd.ParseFromString(data)\n",
    "    tf.import_graph_def(gd, name='')\n",
    "    graph = tf.get_default_graph()\n",
    "    input_image = graph.get_tensor_by_name('input_image:0')\n",
    "    softmax = graph.get_tensor_by_name('softmax:0')\n",
    "    crop_up = 102\n",
    "    crop_down = 518\n",
    "    image_shape = [600,800,3]\n",
    "    results = []\n",
    "    f = 1\n",
    "    c_tp = 0\n",
    "    c_se = 0\n",
    "    c_re = 0\n",
    "    r_tp = 0\n",
    "    r_se = 0\n",
    "    r_re = 0\n",
    "    for image_file in image_paths:\n",
    "        image_raw, label_raw = read_image_label_raw(image_file, label_paths)\n",
    "        image, label = process_raw_data(image_raw, label_raw, crop=(0,600))\n",
    "        crop_frame = np.expand_dims(image[crop_up:crop_down,:,:],0)\n",
    "        out = sess.run(softmax, feed_dict={input_image: crop_frame})[0]\n",
    "        out_arg = np.argmax(out,axis = 2)\n",
    "        # Look for red cars :)\n",
    "        binary_car_result = np.where(out_arg == 1,1,0)\n",
    "        binary_car_result = np.concatenate((np.zeros([crop_up,image_shape[1]]),binary_car_result), axis=0)\n",
    "        binary_car_result = np.concatenate((binary_car_result, np.zeros([image_shape[0]-crop_down,image_shape[1]])), axis=0)\n",
    "        # Look for road :)\n",
    "        binary_road_result = np.where(out_arg == 2,1,0)\n",
    "        binary_road_result = np.concatenate((np.zeros([crop_up,image_shape[1]]),binary_road_result), axis=0)\n",
    "        binary_road_result = np.concatenate((binary_road_result, np.zeros([image_shape[0]-crop_down,image_shape[1]])), axis=0)\n",
    "        results.append(paste_mask(image, binary_car_result, binary_road_result))\n",
    "        # Compute Recall and Precision\n",
    "        c_tp += np.sum(binary_car_result * label[:,:,1])\n",
    "        c_se += np.sum(binary_car_result)\n",
    "        c_re += np.sum(label[:,:,1])\n",
    "        r_tp += np.sum(binary_road_result * label[:,:,2])\n",
    "        r_se += np.sum(binary_road_result)\n",
    "        r_re += np.sum(label[:,:,2])\n",
    "        print('Processing frame: {0}/{1}'.format(f,len(image_paths)),end='\\r')\n",
    "        f +=1\n",
    "    c_P = c_tp/c_se\n",
    "    c_R = c_tp/c_re\n",
    "    r_P = r_tp/r_se\n",
    "    r_R = r_tp/r_re\n",
    "    print(\"Car Precision: {0:.3g} | Car Recall: {1:.3g} | Road Precision: {2:.3g} | Road Recall: {3:.3g} \".format(c_P,c_R,r_P,r_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image sequence to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./videos/test.mp4\n",
      "[MoviePy] Writing video ./videos/test.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 108.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./videos/test.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join('./videos','test.mp4')\n",
    "output_clip = ImageSequenceClip(results, fps=10)\n",
    "output_clip.write_videofile(output_path, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"./videos/test.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
